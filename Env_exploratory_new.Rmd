---
title: "Exploratoring environmental data"
author: "RJ"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, encoding = "UTF_8")


library(ggplot2)
library(lubridate)
library(sf)
library(shiny)
library(htmlwidgets)
library(gapminder)
library(plotly)
library(dplyr)
library(tidyr)
library(maptools)
library(data.table)
library(Imap)
library(httr)
library(ncdf4) # to get what's needed from ncdf files

# set to fractional seconds
op <- options(digits.secs=3)


# let's do this around infrasound and barometric pressure
path_to_env_files <- "./DataBaseOllieNew/"
ID_folders <- dir(path_to_env_files, pattern = "ID")

# let's do this for the 1st bird
x <-10 # first ID
path_to_trips <- paste0(path_to_env_files, ID_folders[x], "/")
ID_trips_folders <- dir(path_to_trips)

x_trip <-2 # second trip for the ID
path_to_ncdf <- paste0(path_to_trips, ID_trips_folders[x_trip], "/netCDF/")
```

# ID
```{r animal1, include=TRUE}
path_to_ncdf
```

## Pressure

```{r Pressure , echo=FALSE, include = F}
# open Barometric pressure file
path_to_ncdf_baro <- paste0(path_to_ncdf, "Baro/")
baro_name <- dir(path_to_ncdf_baro, pattern = "Barometerdata")

nc_file <- nc_open(paste0(path_to_ncdf_baro, baro_name))
print(nc_file) # getting all the characteristics of the file


Pressure_matrix <- t(ncvar_get(nc_file, "Barodata"))
nc_close(nc_file)
Pressure_df <- as.data.frame(Pressure_matrix)
colnames(Pressure_df) <- c("Time","Pressure_hPa")


str(Pressure_df)
Pressure_df$Time_o<-Pressure_df$Time #time original
Pressure_df$Time <- as.POSIXct(Pressure_df$Time, tz="GMT", origin = "1970-01-01 00:00:00") + hours(5) # adding time difference with Crozet, so to be in local time rather than UTC. 
head(Pressure_df$Time) 
#Pressure_df<-Pressure_df[Pressure_df[,"Time"]<= "2020-02-17 04:00:00",]#select only data collected before the 17th of Feb for ID101_2_IS_BC1 x=1 trip=1
#Pressure_df<-Pressure_df[Pressure_df[,"Time"]<= "2020-02-12 18:00:00",]#select only data collected before the 12th of Feb for ID101/Trip_FU4 x=1 trip=1


# #statistic metric
# #create  an index fore each 5 minutes bout every hour.

Presres<-diff(Pressure_df$Time_o)#  estimate the time between each sample taken. 
summary(Presres)# the median should be around 0.1, which is relates with 10 samples taken in a second, i.e., sample frequency of 10Hz.
Presres3<-c(Presres,0)
Pressure_df3<- cbind(Presres3,Pressure_df)


# the logger is programmed to take10 samples within a second for about 1 consecutive minute (600 samples). However sometimes there is are less than 10 samples taken within a second, and they could be taken for longer than a minute.  To select when a new bout starts 
#we define this as when the time difference between each sample is bigger than 50, i.e., more than 5 seconds without taking any sample. 
bout_st<-c(0,which(Pressure_df3$Presres3>50))
diff(bout_st)# this gives the number of samples within each bout.
sum(diff(bout_st))# check that this is the same as the number of values within Pressure_df3
lastp<-length(Pressure_df3$Presres3)-sum(diff(bout_st))
idx<-c(diff(bout_st),lastp)# this is the last point taken for each bout. 
Pressure_df3$group=(rep(1:length(idx),times=idx))# we divide the data in bouts. 

#provide number of points in each bout
tabla<-Pressure_df3%>%group_by(group)%>%summarise(median_BaromP=median(Pressure_hPa,na.rm = T),
                                           mean_BaromP=mean(Pressure_hPa,na.rm = T),
                                           min_BaromP=min(Pressure_hPa,na.rm = T),
                                           max_BaromP=max(Pressure_hPa,na.rm = T),
                                           first_Qu_BaromP=quantile(Pressure_hPa,probs = 0.25,na.rm = T),
                                           third_Qu_BaromP=quantile(Pressure_hPa,probs = 0.75,na.rm = T),
                                           count=n(),
                                           first_value = first(na.omit(Time_o))
                                           )
#Calculate the inter bout interval.
tabla$IBI<- c(0,diff(tabla$first_value))# it should be approx one per hour

tabla_global<-Pressure_df3%>%summarise(median_BaromP=median(Pressure_hPa,na.rm = T),
                                           mean_BaromP=mean(Pressure_hPa,na.rm = T),
                                           min_BaromP=min(Pressure_hPa,na.rm = T),
                                           max_BaromP=max(Pressure_hPa,na.rm = T),
                                           first_Qu_BaromP=quantile(Pressure_hPa,probs = 0.25,na.rm = T),
                                           third_Qu_BaromP=quantile(Pressure_hPa,probs = 0.75,na.rm = T)
)
                                      
tabla_global$mean_IBI_sec<-mean(tabla$IBI)
tabla_global$mean_samples_within_bout<-mean(tabla$count)
tabla_global$tot_group_n<-max(tabla$group)

```

### Some context for each track's pressure data 

* Source: Ollie's notebooks and email exchanges between Jelle, Ollie and me

* The data are not calibrated yet.
* Since there should be more or less 5-min segments of data every hour, the raw data at 10 Hz are first divided into 5 minute segments (or 15, but it will only contain 5)
* Data cleaning is done on these segments. So, each segments:
  * Assuming that barometric pressure distributes normally --Jelle said it's a safe assumption --, outliers are filtered out by first obtaining z-scores (gives you an idea of how far from the mean a data point is. But more technically it's a measure of how many standard deviations below or above the population mean a raw score is)
  and keeping the observations whose absolute z-scores are below 3. 
  * Then, if consecutive observations show a difference greater than 2hPa (meaning a ~20m difference),
  the following value is replaced by the preceding value. 
* Resampling is done at 1 Hz. It is basically done by fitting sinusoids to the data (Fast Fourier Transform) and then taking value points. We're using the obspy.resample function in python which is a wrapper of scipy.signal.resample
* Everything is saved into a netCDF file



## Time series


```{r Pressure2 , echo=FALSE, include = T}
# paste("number of observations is", nrow(Pressure_df))
# paste("summary diff time Pressure sensor in Hz", summary(Presres))
# paste("Min, 1st Qu, Median, Mean, 3rdQu, Max")

# as.data.frame(tabla)
as.data.frame(tabla_global)


```
### Variability within each 5 mins bout in BP
black point: mean
blueish bars for min and max
greenish bars for q1 and q3 
greenish dash lines link medians

```{r Pressure graph , echo=FALSE, include = TRUE, out.width = '200%'}
# Color-blind friendly palette from http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette
# The palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
ggplot(data = tabla, aes(x = group)) +
  geom_point(aes(y = mean_BaromP), cex = 0.5)  + # black points as means
  geom_errorbar(aes(ymin = min_BaromP, ymax = max_BaromP), color =  cbbPalette[3]) + # blueish bars for min and max
  geom_errorbar(aes(ymin = first_Qu_BaromP, ymax = third_Qu_BaromP), color =  cbbPalette[4]) + # greenish bars for q1 and q3
  geom_line(aes(y = median_BaromP), color = cbbPalette[4], linetype = 3) + # greenish dash lines linking medians
  labs(y = "stats", x = "time intervals") +
  scale_y_continuous(limits=c(floor(min(tabla$min_BaromP)),ceiling(max(tabla$max_BaromP)))) +
  theme_bw()
```

### Now without max and min
black points: mean
squares medians
greenish bars for q1 and q3 
greenish dash lines link medians

```{r Pressure graph 2 , echo=FALSE, include = TRUE, out.width = '200%'}
# Color-blind friendly palette from http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette
# The palette with black:
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
ggplot(data = tabla, aes(x = group)) +
  geom_errorbar(aes(ymin = first_Qu_BaromP, ymax = third_Qu_BaromP), color =  cbbPalette[4]) + # greenish bars for q1 and q3
  geom_line(aes(y = median_BaromP), color = cbbPalette[4], linetype = 3) + # greenish dash lines linking medians
  geom_point(aes(y = mean_BaromP), cex = 0.5)  + # black points as means
  geom_point(aes(y = median_BaromP), cex = 0.5, shape = 22, color = cbbPalette[6])  + # squares as medians
  labs(y = "stats", x = "time intervals") +
  scale_y_continuous(limits=c(floor(min(tabla$min_BaromP)),ceiling(max(tabla$max_BaromP)))) +
  theme_bw()

```

### Data to check
Here is plotted how data should look like in first plot

Second plot shows the data within each bout for which the median and the mean differs by more than 0.3hPa. 

```{r PressureTS , echo=FALSE, warning=FALSE}

###create an interactive figure to see how a bout with a difference of less than 0.3 hPa between the mean and the median looks like. 
datapool<-unlist(c(tabla[abs(tabla$median_BaromP-tabla$mean_BaromP)<0.3,1]))
datagood<-sample(datapool,1)

data2plot_good<-Pressure_df3[Pressure_df3$group==datagood,]
pPresTS2 <- data2plot_good %>%
     ggplot(aes(x =Time_o, y = Pressure_hPa)) +
     geom_point(aes(color = Pressure_hPa),size=0.5)+
     scale_colour_viridis_c(option = "magma", direction = -1) +
     theme_minimal()
 ggplotly(pPresTS2,
          dynamicTicks = TRUE, session="knitr")
 
###create an interactive figure to inspect those points with a difference of 0.3 hPa between the mean and the median.
# data2check<-unlist(c(tabla[abs(tabla$median_BaromP-tabla$mean_BaromP)>0.3,1]))
# 
# data2plot_full <- NULL# prepare a container
# for (i in 1:length(data2check))
# {
#   data2plot<-Pressure_df3[Pressure_df3$group==data2check[i],]
#   data2plot_full<-rbind(data2plot_full,data2plot)
#   #create a plot for each bout that needs inspection
# }
# 
# pPresTS <- data2plot_full %>%
#      ggplot(aes(x =Time, y = Pressure_hPa)) +
#      geom_point(aes(color = Pressure_hPa),size=0.5)+
#      scale_colour_viridis_c(option = "magma", direction = -1) +
#      theme_minimal()+
#      facet_wrap(~group)
#  ggplotly(pPresTS,
#           dynamicTicks = TRUE, session="knitr")

#data <- Pressure_df3[1:15000,]
# m0 <- highlight_key(data)
# p0<-  ggplot(m0, aes(x =Time, y = Pressure_hPa)) +
#   geom_point(aes(color = Pressure_hPa),size=0.5)+
#   scale_colour_viridis_c(option = "magma", direction = -1) +
#   theme_minimal()
# gg0 <- highlight(ggplotly(p0), "plotly_selected")
# crosstalk::bscols(gg0, DT::datatable(m0))# 



plot(Pressure_df$Time, Pressure_df$Pressure_hPa)

```

## Infrasound

### Some context for each track's infrasound data

* Source: Ollie's notebooks, email exchanges between Jelle, Ollie and me, some reading and youtube videos

* The data are calibrated.
* Since there should be more or less 5-min segments of data every hour (could be 1), the raw data at 10 Hz are first divided into 5 minute segments (or 15, but it will only contain 5)
* Data cleaning is done on these segments. So, each segments:
  * Assuming that absolute pressure distributes normally, outliers are filtered out by first obtaining z-scores
  and keeping the observations whose absolute z-scores are below 3.
  * Then, if consecutive observations show a difference greater than 10 (I don't know why 10),
  the following value is replaced by the preceding value.
* No resampling
* For each segment, the power spectral density is estimated using Welch's method;
  it basically divides data into overlapping segments, computing a modified periodogram for
  each segment and averaging the periodograms
* The PSD data are transformed to obtain SPL as $10 \times \log(PSD/(2*10^{-5})*2))$
* The SPL data are saved into a netCDF file


```{r Infrasound , echo=FALSE, include = F}
# open Infrasound file


path_to_ncdf_sound <- paste0(path_to_ncdf, "Infrasd/")
sound_name <- dir(path_to_ncdf_sound, pattern = "SPL")
nc_file <- nc_open(paste0(path_to_ncdf_sound, sound_name))
print(nc_file) # getting all the characteristics of the file

# getting the names of the columns
names_var <- names(nc_file$var)
names_var <- names_var[1:(length(names_var)-1)]
SPL_Matrix <- ncvar_get(nc_file, "SPLdata")
nc_close(nc_file)
SPL_df <- as.data.frame(SPL_Matrix)
colnames(SPL_df) <- c("Time")
str(SPL_df)
Freq <- SPL_df[1,2:dim(SPL_df)[2]] # These are the frequencies for SPL - for ID111_2_IS_DT5 SPL_df[13,2:dim(SPL_df)[2]]
SPL_df <- SPL_df[-1,]#  remove first row
SPL_df$Time_o<-SPL_df$Time
SPL_df$Time <- as.POSIXct(SPL_df$Time, tz="GMT", origin = "1970-01-01 00:00:00") + hours(5)
# We may not be interested in each frequency for now
#

# We'll make two categories of SPL: 0.07-1 and 1-5
SPL_low <- apply(as.data.frame(SPL_df[,which(Freq < 1 & Freq > 0.07)+1]),1,mean)# what does the -inf mean?
SPL_high <- apply(SPL_df[,which(Freq > 1)+1],1,mean)
SPL_cat <- data.frame(Time=SPL_df[,1], SPL_low=SPL_low, SPL_high=SPL_high)




tabla_global_SPL<-NULL
tabla_global_SPL$tot_group_n<-nrow(SPL_cat)
tabla_global_SPL$mean_IBI<-mean(diff(SPL_df$Time_o))



```

### Time series of Sound Pressure Level from Low Infrasound (0.07-1Hz)
```{r SPLlowTS2 , echo=FALSE, include = T}
as.data.frame(tabla_global_SPL)
```

```{r SPLlowTS , echo=FALSE}
###create an interactive figure of lat long using ggplotly with the colony point
data <- SPL_cat
pSPLlowTS <- data %>%
  ggplot(aes(x =Time, y = SPL_low)) +
  geom_point(aes(color = SPL_low),size=0.5)+
  scale_colour_viridis_c(option = "magma", direction = -1) +
  theme_minimal()
ggplotly(pSPLlowTS,
         dynamicTicks = TRUE, session="knitr")

```

### Time series of Sound Pressure Level from High Infrasound (1-4Hz)
```{r SPLhighTS , echo=FALSE}
###create an interactive figure of lat long using ggplotly with the colony point
data <- SPL_cat
pSPLhighTS <- data %>%
  ggplot(aes(x =Time, y = SPL_high)) +
  geom_point(aes(color = SPL_high),size=0.5)+
  scale_colour_viridis_c(option = "magma", direction = -1) +
  theme_minimal()
ggplotly(pSPLhighTS,
         dynamicTicks = TRUE, session="knitr")

```

